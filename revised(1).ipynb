{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find the \"Best\" Doc2Vec Model Using Coefficient of Variation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspired by the idea used in PCA that singular valures represent the amount of information of a matrix, we believe that the 'best' Doc2vec model has the lowest variance in the singular values of its word vectors. **That is to say, every dimension of a word vector captures the same amount of information.**     \n",
    "However, variance of the singular values only tells part of the story. **Coefficient of variation is able to better describe the \"magnitude\" of the variation in singular values.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evalute(docvectors):\n",
    "    U,s,V = np.linalg.svd(docvectors)# perform singular value decomposition on the word vectors\n",
    "    return np.std(s)/np.mean(s)# calculate the Coefficient of Variation of the singular values\n",
    "\n",
    "def doctrain(size, window):\n",
    "    doc2vec = Doc2Vec(size=size, window=window, min_count=5, dm = 1, workers=2, iter=30)\n",
    "    doc2vec.build_vocab(tagged_docs)\n",
    "    doc2vec.train(tagged_docs, epochs=10, total_examples=doc2vec.corpus_count)\n",
    "    return np.array(doc2vec.docvecs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exhaustive Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {'window': [1, 2, 3, 4, 5, 6, 7], \n",
    "             'size': [ 100, 200, 300, 400]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size: 100 | Window: 1 | score: 0.9358351826667786\n",
      "Size: 100 | Window: 2 | score: 0.9395149946212769\n",
      "Size: 100 | Window: 3 | score: 0.9446083903312683\n",
      "Size: 100 | Window: 4 | score: 0.9481077790260315\n",
      "Size: 100 | Window: 5 | score: 0.9489095211029053\n",
      "Size: 100 | Window: 6 | score: 0.9506281614303589\n",
      "Size: 100 | Window: 7 | score: 0.9517930150032043\n",
      "Size: 200 | Window: 1 | score: 1.3784544467926025\n",
      "Size: 200 | Window: 2 | score: 1.4091984033584595\n",
      "Size: 200 | Window: 3 | score: 1.4339606761932373\n",
      "Size: 200 | Window: 4 | score: 1.4454121589660645\n",
      "Size: 200 | Window: 5 | score: 1.4537146091461182\n",
      "Size: 200 | Window: 6 | score: 1.4602776765823364\n",
      "Size: 200 | Window: 7 | score: 1.4659299850463867\n",
      "Size: 300 | Window: 1 | score: 1.7742098569869995\n",
      "Size: 300 | Window: 2 | score: 1.8187713623046875\n",
      "Size: 300 | Window: 3 | score: 1.8469626903533936\n",
      "Size: 300 | Window: 4 | score: 1.869125247001648\n",
      "Size: 300 | Window: 5 | score: 1.8786348104476929\n",
      "Size: 300 | Window: 6 | score: 1.8936400413513184\n",
      "Size: 300 | Window: 7 | score: 1.902235746383667\n",
      "Size: 400 | Window: 1 | score: 2.1086292266845703\n",
      "Size: 400 | Window: 2 | score: 2.1680996417999268\n",
      "Size: 400 | Window: 3 | score: 2.2066280841827393\n",
      "Size: 400 | Window: 4 | score: 2.2247135639190674\n",
      "Size: 400 | Window: 5 | score: 2.2457597255706787\n",
      "Size: 400 | Window: 6 | score: 2.2562203407287598\n",
      "Size: 400 | Window: 7 | score: 2.269705295562744\n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "result = {}\n",
    "for size, window in product(params['size'], params['window']):\n",
    "    docvectors = doctrain(size, window)\n",
    "    score = evalute(docvectors)\n",
    "    result[(window, size)] = score\n",
    "    print('Size: {} | Window: {} | score: {}'.format(size, window, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doc2vec = Doc2Vec(size=100, window=1, min_count=5, dm = 1, workers=2, iter=30)#best Doc2vec model generated by grid search\n",
    "doc2vec.build_vocab(tagged_docs)\n",
    "doc2vec.train(tagged_docs, epochs=10, total_examples=doc2vec.corpus_count)\n",
    "doc2vec.save('D:/Work/fake-news/doc2vec-100dm-w1.bin.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result suggests that the 'best' Doc2Vec model is the one with the size of 100 and window of 1. **However, given the size of our data set, we believe that it would be better to have some more information about the ralations between words and paragraphs. Thus we decide to fortify our Doc2Vec models by Google News Word2Vec model and to find the 'best' model among the fortified ones.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fortified Doc2Vec Model Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def doctrain_fortified(size, window):\n",
    "    doc2vec = Doc2Vec(size=size, window=window, min_count=5, dm = 1, workers=2, iter=30)\n",
    "    doc2vec.build_vocab(tagged_docs)\n",
    "    w2v_loc = 'D:/Work/fake-news/GoogleNews-vectors-negative300.bin.gz'\n",
    "    doc2vec.intersect_word2vec_format(w2v_loc, binary=True)\n",
    "    doc2vec.train(tagged_docs, epochs=10, total_examples=doc2vec.corpus_count)\n",
    "    return np.array(doc2vec.docvecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size: 300 | Window: 1 | score: 0.9168175458908081\n",
      "Size: 300 | Window: 2 | score: 1.0319315195083618\n",
      "Size: 300 | Window: 3 | score: 1.1303040981292725\n",
      "Size: 300 | Window: 4 | score: 1.2096953392028809\n",
      "Size: 300 | Window: 5 | score: 1.2759608030319214\n",
      "Size: 300 | Window: 6 | score: 1.333014965057373\n",
      "Size: 300 | Window: 7 | score: 1.3782696723937988\n",
      "Size: 300 | Window: 8 | score: 1.418958306312561\n"
     ]
    }
   ],
   "source": [
    "params = {'window': [1, 2, 3, 4, 5, 6, 7, 8]}\n",
    "for window in params['window']:\n",
    "    docvectors = doctrain_fortified(300, window)\n",
    "    score = evalute(docvectors)\n",
    "    print('Size: 300 | Window: {} | score: {}'.format(window, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doc2vec = Doc2Vec(size=300, window=1, min_count=5, dm = 1, \n",
    "                  workers=2, iter=30)#best fortified Doc2vec model generated by grid search\n",
    "doc2vec.build_vocab(tagged_docs)\n",
    "w2v_loc = 'D:/Work/fake-news/GoogleNews-vectors-negative300.bin.gz'\n",
    "doc2vec.intersect_word2vec_format(w2v_loc, binary=True)\n",
    "doc2vec.train(tagged_docs, epochs=10, total_examples=doc2vec.corpus_count)\n",
    "doc2vec.save('D:/Work/fake-news/doc2vec-w1-fortified.bin.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best model appears to be the one with window 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We choose two Doc2Vec models with the lowest coefficient of cariation as the best models for hypertuning.     \n",
    "**No.1: Size=100, Window=1**    \n",
    "**No.2: Size=300, Window=1, Fortified by Google News Word2Vec Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1: Weighted Sum of Title Vectors and Text Vectors with XGBoost Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8476</td>\n",
       "      <td>You Can Smell Hillary’s Fear</td>\n",
       "      <td>Daniel Greenfield, a Shillman Journalism Fello...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10294</td>\n",
       "      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n",
       "      <td>Google Pinterest Digg Linkedin Reddit Stumbleu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3608</td>\n",
       "      <td>Kerry to go to Paris in gesture of sympathy</td>\n",
       "      <td>U.S. Secretary of State John F. Kerry said Mon...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10142</td>\n",
       "      <td>Bernie supporters on Twitter erupt in anger ag...</td>\n",
       "      <td>— Kaydee King (@KaydeeKing) November 9, 2016 T...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>875</td>\n",
       "      <td>The Battle of New York: Why This Primary Matters</td>\n",
       "      <td>It's primary day in New York and front-runners...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6903</td>\n",
       "      <td>Tehran, USA</td>\n",
       "      <td>\\nI’m not an immigrant, but my grandparents ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7341</td>\n",
       "      <td>Girl Horrified At What She Watches Boyfriend D...</td>\n",
       "      <td>Share This Baylee Luciani (left), Screenshot o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>95</td>\n",
       "      <td>‘Britain’s Schindler’ Dies at 106</td>\n",
       "      <td>A Czech stockbroker who saved more than 650 Je...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4869</td>\n",
       "      <td>Fact check: Trump and Clinton at the 'commande...</td>\n",
       "      <td>Hillary Clinton and Donald Trump made some ina...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2909</td>\n",
       "      <td>Iran reportedly makes new push for uranium con...</td>\n",
       "      <td>Iranian negotiators reportedly have made a las...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              title  \\\n",
       "0        8476                       You Can Smell Hillary’s Fear   \n",
       "1       10294  Watch The Exact Moment Paul Ryan Committed Pol...   \n",
       "2        3608        Kerry to go to Paris in gesture of sympathy   \n",
       "3       10142  Bernie supporters on Twitter erupt in anger ag...   \n",
       "4         875   The Battle of New York: Why This Primary Matters   \n",
       "5        6903                                        Tehran, USA   \n",
       "6        7341  Girl Horrified At What She Watches Boyfriend D...   \n",
       "7          95                  ‘Britain’s Schindler’ Dies at 106   \n",
       "8        4869  Fact check: Trump and Clinton at the 'commande...   \n",
       "9        2909  Iran reportedly makes new push for uranium con...   \n",
       "\n",
       "                                                text  label  \n",
       "0  Daniel Greenfield, a Shillman Journalism Fello...      0  \n",
       "1  Google Pinterest Digg Linkedin Reddit Stumbleu...      0  \n",
       "2  U.S. Secretary of State John F. Kerry said Mon...      1  \n",
       "3  — Kaydee King (@KaydeeKing) November 9, 2016 T...      0  \n",
       "4  It's primary day in New York and front-runners...      1  \n",
       "5    \\nI’m not an immigrant, but my grandparents ...      0  \n",
       "6  Share This Baylee Luciani (left), Screenshot o...      0  \n",
       "7  A Czech stockbroker who saved more than 650 Je...      1  \n",
       "8  Hillary Clinton and Donald Trump made some ina...      1  \n",
       "9  Iranian negotiators reportedly have made a las...      1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('D:/Work/fake-news/fake_or_real_news.csv')\n",
    "df.label = df.label.replace({\"FAKE\":0, \"REAL\":1})  #replace 'FAKE' as 0, 'REAL' as 1\n",
    "df = df.drop('title_vectors',1)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "def clean_list(tokenized_list):\n",
    "    import string \n",
    "    sw = nltk.corpus.stopwords.words('english')\n",
    "    extend = ['https', 'http', '•', '”', '“','—',\"n't\",'’',\"'s\"]\n",
    "    sw = sw + extend\n",
    "    new_list = [[token.lower() for token in tlist if token not in string.punctuation and token.lower() not in sw] for tlist in tokenized_list]\n",
    "    return new_list\n",
    "\n",
    "title = [nltk.word_tokenize(i) for i in df.title]\n",
    "text = [nltk.word_tokenize(i) for i in df.text]\n",
    "\n",
    "title = clean_list(title)\n",
    "text = clean_list(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  1.1 Hypertuning for Doc2Vec size:100 window:1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.1 Get Tile Vectors and Text Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models import Doc2Vec\n",
    "doc2vec = Doc2Vec.load('D:/Work/fake-news/doc2vec-100dm_w1.bin.gz')#load the doc2vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_vectors = [doc2vec.infer_vector(i) for i in text]\n",
    "title_vectors = [doc2vec.infer_vector(i) for i in title]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_vector=np.array(text_vectors)\n",
    "title_vector=np.array(title_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_text = text_vector\n",
    "X_title = title_vector\n",
    "y = np.array(df.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "v_params = [0, 0.1, 0.2, 0.4, 0.5, 0.6] #set different weights for title vectors and text vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from time import time\n",
    "from scipy.stats import randint as sp_randint\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn import cross_validation, metrics\n",
    "from sklearn.grid_search import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "        \n",
    "XGBmodel = XGBClassifier(booster='gbtree', n_jobs=2, objective='binary:logistic')\n",
    "\n",
    "\n",
    "param_dist = {\"n_estimators\": sp_randint(1000, 5000),\n",
    "              \"learning_rate\": [0.01, 0.05, 0.1, 0.15, 0.2],\n",
    "              \"min_child_weight\": sp_randint(1, 10),\n",
    "              \"max_depth\": sp_randint(1,15)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2 Find the Best Parameters for XGBoost Classifier Using Randomized Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomizedSearchCV took 1411.46 seconds for 20 candidates parameter settings.\n",
      "v_param: 0\n",
      "best params: {'learning_rate': 0.01, 'max_depth': 4, 'min_child_weight': 4, 'n_estimators': 2052}\n",
      "score: 0.8972667295004713\n",
      "RandomizedSearchCV took 1048.01 seconds for 20 candidates parameter settings.\n",
      "v_param: 0.1\n",
      "best params: {'learning_rate': 0.1, 'max_depth': 5, 'min_child_weight': 5, 'n_estimators': 4261}\n",
      "score: 0.8989161168708766\n",
      "RandomizedSearchCV took 1027.19 seconds for 20 candidates parameter settings.\n",
      "v_param: 0.2\n",
      "best params: {'learning_rate': 0.05, 'max_depth': 3, 'min_child_weight': 2, 'n_estimators': 3748}\n",
      "score: 0.8989161168708766\n",
      "RandomizedSearchCV took 1115.54 seconds for 20 candidates parameter settings.\n",
      "v_param: 0.4\n",
      "best params: {'learning_rate': 0.05, 'max_depth': 7, 'min_child_weight': 8, 'n_estimators': 1275}\n",
      "score: 0.897502356267672\n",
      "RandomizedSearchCV took 1017.76 seconds for 20 candidates parameter settings.\n",
      "v_param: 0.5\n",
      "best params: {'learning_rate': 0.2, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 3834}\n",
      "score: 0.8972667295004713\n",
      "RandomizedSearchCV took 944.55 seconds for 20 candidates parameter settings.\n",
      "v_param: 0.6\n",
      "best params: {'learning_rate': 0.1, 'max_depth': 4, 'min_child_weight': 1, 'n_estimators': 2349}\n",
      "score: 0.8953817153628653\n"
     ]
    }
   ],
   "source": [
    "for v in v_params:\n",
    "    X = v*X_title + (1-v)*X_text\n",
    "    \n",
    "    random_state = 42\n",
    "\n",
    "    test_size = .33\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = test_size,\n",
    "                                                              random_state = random_state)\n",
    "    n_iter_search = 20\n",
    "\n",
    "    random_search = RandomizedSearchCV(XGBmodel, param_distributions=param_dist, n_iter=n_iter_search)\n",
    "    start = time()\n",
    "    \n",
    "    random_search.fit(X_train, y_train)\n",
    "    print(\"RandomizedSearchCV took %.2f seconds for %d candidates\"\n",
    "      \" parameter settings.\" % ((time() - start), n_iter_search))\n",
    "    print(\"v_param:\",v)\n",
    "    print(\"best params:\",random_search.best_params_)\n",
    "    print(\"score:\",random_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The result of grid search indicates that the best parameter for weighted sum of the vectors is 0.2**     \n",
    "**The best parameters for XGBoostClassifier are: learning_rate = 0.05 max_depth = 3, n_estimators = 3700, min_child_weight = 2**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.3 Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**v=0.2 Hypertuned XGBoost**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.05, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=2, missing=None, n_estimators=3700,\n",
       "       n_jobs=2, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = 0.2\n",
    "X = v*X_title + (1-v)*X_text\n",
    "    \n",
    "random_state = 42\n",
    "test_size = .33\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = test_size,\n",
    "                                                              random_state = random_state)\n",
    "\n",
    "XGBmodel = XGBClassifier(booster='gbtree', n_jobs=2, objective='binary:logistic', learning_rate = 0.05, \n",
    "                         max_depth = 3, min_child_weight = 2, n_estimators =3700)\n",
    "XGBmodel.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.4 Model Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Fake       0.90      0.91      0.91      1071\n",
      "       Real       0.91      0.90      0.90      1020\n",
      "\n",
      "avg / total       0.90      0.90      0.90      2091\n",
      "\n",
      "Accuracy: 0.904830224773\n"
     ]
    }
   ],
   "source": [
    "y_pred = XGBmodel.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "target_names = ['Fake', 'Real']\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "print('Accuracy:',XGBmodel.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Hypertuning for Fortified Doc2Vec size:300 window:1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.1 Get Tile Vectors and Text Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models import Doc2Vec\n",
    "doc2vec = Doc2Vec.load('D:/Work/fake-news/doc2vec-w1-fortified.bin.gz')#load the fortified doc2vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_vectors = [doc2vec.infer_vector(i) for i in text]\n",
    "title_vectors = [doc2vec.infer_vector(i) for i in title]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_vector=np.array(text_vectors)\n",
    "title_vector=np.array(title_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_text = text_vector\n",
    "X_title = title_vector\n",
    "y = np.array(df.label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2 Find the Best Parameters for XGBoost Classifier Using Randomized Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from time import time\n",
    "from scipy.stats import randint as sp_randint\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn import cross_validation, metrics\n",
    "from sklearn.grid_search import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "v_params = [0, 0.2, 0.4, 0.5, 0.6]\n",
    "param_dist = {\"n_estimators\": sp_randint(1000, 5000),\n",
    "              \"learning_rate\": [0.01, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3],\n",
    "              \"min_child_weight\": sp_randint(1, 10),\n",
    "              \"max_depth\": sp_randint(1,10)}\n",
    "XGBmodel = XGBClassifier(booster='gbtree', n_jobs=2, objective='binary:logistic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomizedSearchCV took 2160.58 seconds for 20 candidates parameter settings.\n",
      "v_param: 0\n",
      "best params: {'learning_rate': 0.05, 'max_depth': 8, 'min_child_weight': 5, 'n_estimators': 1879}\n",
      "score: 0.90315739868049\n",
      "RandomizedSearchCV took 2386.16 seconds for 20 candidates parameter settings.\n",
      "v_param: 0.2\n",
      "best params: {'learning_rate': 0.1, 'max_depth': 4, 'min_child_weight': 3, 'n_estimators': 3815}\n",
      "score: 0.9064561734213007\n",
      "RandomizedSearchCV took 1872.04 seconds for 20 candidates parameter settings.\n",
      "v_param: 0.4\n",
      "best params: {'learning_rate': 0.2, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 2670}\n",
      "score: 0.9104618284637135\n",
      "RandomizedSearchCV took 2393.51 seconds for 20 candidates parameter settings.\n",
      "v_param: 0.5\n",
      "best params: {'learning_rate': 0.05, 'max_depth': 3, 'min_child_weight': 5, 'n_estimators': 2605}\n",
      "score: 0.9076343072573044\n",
      "RandomizedSearchCV took 2022.28 seconds for 20 candidates parameter settings.\n",
      "v_param: 0.6\n",
      "best params: {'learning_rate': 0.05, 'max_depth': 3, 'min_child_weight': 4, 'n_estimators': 1445}\n",
      "score: 0.9017436380772855\n"
     ]
    }
   ],
   "source": [
    "for v in v_params:\n",
    "    X = v*X_title + (1-v)*X_text\n",
    "    \n",
    "    random_state = 42\n",
    "\n",
    "    test_size = .33\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = test_size,\n",
    "                                                              random_state = random_state)\n",
    "    n_iter_search = 20\n",
    "\n",
    "    random_search = RandomizedSearchCV(XGBmodel, param_distributions=param_dist, n_iter=n_iter_search)\n",
    "    start = time()\n",
    "    \n",
    "    random_search.fit(X_train, y_train)\n",
    "    print(\"RandomizedSearchCV took %.2f seconds for %d candidates\"\n",
    "      \" parameter settings.\" % ((time() - start), n_iter_search))\n",
    "    print(\"v_param:\",v)\n",
    "    print(\"best params:\",random_search.best_params_)\n",
    "    print(\"score:\",random_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.3 Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**v=0.2  Hypertuned XGBoost**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=4, min_child_weight=3, missing=None, n_estimators=3800,\n",
       "       n_jobs=2, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = 0.2\n",
    "X = v*X_title + (1-v)*X_text\n",
    "\n",
    "random_state = 42\n",
    "\n",
    "test_size = .33\n",
    "\n",
    "X_train, X_test, y_train, y_test= train_test_split(X, y, test_size = test_size,\n",
    "                                                              random_state = random_state)\n",
    "XGBmodel = XGBClassifier(booster='gbtree', n_jobs=2, objective='binary:logistic', learning_rate = 0.1, \n",
    "                         max_depth = 4, min_child_weight = 3, n_estimators = 3800)\n",
    "XGBmodel.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**v=0.4 Hypertuned XGBoost**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.2, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=2700,\n",
       "       n_jobs=2, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = 0.4\n",
    "X = v*X_title + (1-v)*X_text\n",
    "\n",
    "random_state = 42\n",
    "\n",
    "test_size = .33\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = test_size,\n",
    "                                                              random_state = random_state)\n",
    "XGBmodel = XGBClassifier(booster='gbtree', n_jobs=2, objective='binary:logistic', learning_rate = 0.2, \n",
    "                         max_depth = 3, min_child_weight = 1, n_estimators = 2700)\n",
    "XGBmodel.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.4 Model Result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**v=0.2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Fake       0.92      0.92      0.92      1071\n",
      "       Real       0.92      0.91      0.92      1020\n",
      "\n",
      "avg / total       0.92      0.92      0.92      2091\n",
      "\n",
      "Accuracy: 0.918699186992\n"
     ]
    }
   ],
   "source": [
    "y_pred = XGBmodel.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "target_names = ['Fake', 'Real']\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "print('Accuracy:',XGBmodel.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**v=0.4**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Fake       0.92      0.91      0.92      1066\n",
      "       Real       0.91      0.92      0.91      1025\n",
      "\n",
      "avg / total       0.91      0.91      0.91      2091\n",
      "\n",
      "Accuracy: 0.91487326638\n"
     ]
    }
   ],
   "source": [
    "y_pred = XGBmodel.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "target_names = ['Fake', 'Real']\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "print('Accuracy:',XGBmodel.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** It appears that v=0.2 has better result. So we further tuned the XGBoost Classifier by adding up the iteration for grid search**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.5 Further Tuning for v=0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomizedSearchCV took 2858.70 seconds for 40 candidates parameter settings.\n",
      "v_param: 0.2\n",
      "best params: {'colsample_bytree': 0.8, 'gamma': 0.4, 'learning_rate': 0.05, 'max_depth': 2, 'min_child_weight': 2, 'n_estimators': 1672, 'subsample': 0.5}\n",
      "score: 0.9088124410933082\n"
     ]
    }
   ],
   "source": [
    "    param_dist = {\"n_estimators\": sp_randint(1000, 5000),\n",
    "              \"learning_rate\": [0.01, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3],\n",
    "              \"subsample\":[0.2, 0.5, 0.8, 1],\n",
    "              \"gamma\":[0.1, 0.2, 0.3, 0.4],\n",
    "              \"colsample_bytree\":[0.2, 0.4, 0.6, 0.8, 1],\n",
    "              \"min_child_weight\": sp_randint(1, 10),\n",
    "              \"max_depth\": sp_randint(1,10)}\n",
    "    v=0.2\n",
    "    X = v*X_title + (1-v)*X_text\n",
    "    \n",
    "    random_state = 42\n",
    "\n",
    "    test_size = .33\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = test_size,\n",
    "                                                              random_state = random_state)\n",
    "    n_iter_search = 40\n",
    "\n",
    "    random_search = RandomizedSearchCV(XGBmodel, param_distributions=param_dist, n_iter=n_iter_search)\n",
    "    start = time()\n",
    "    \n",
    "    random_search.fit(X_train, y_train)\n",
    "    print(\"RandomizedSearchCV took %.2f seconds for %d candidates\"\n",
    "      \" parameter settings.\" % ((time() - start), n_iter_search))\n",
    "    print(\"v_param:\",v)\n",
    "    print(\"best params:\",random_search.best_params_)\n",
    "    print(\"score:\",random_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**v=0.2 Further Tuned XGBoost**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, gamma=0.4, learning_rate=0.05,\n",
       "       max_delta_step=0, max_depth=2, min_child_weight=2, missing=None,\n",
       "       n_estimators=1700, n_jobs=2, nthread=None,\n",
       "       objective='binary:logistic', random_state=0, reg_alpha=0,\n",
       "       reg_lambda=1, scale_pos_weight=1, seed=None, silent=True,\n",
       "       subsample=1)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = 0.2\n",
    "X = v*X_title + (1-v)*X_text\n",
    "\n",
    "random_state = 42\n",
    "\n",
    "test_size = .33\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = test_size,\n",
    "                                                              random_state = random_state)\n",
    "XGBmodel = XGBClassifier(booster='gbtree', n_jobs=2, objective='binary:logistic', colsample_bytree = 0.8, gamma = 0.4,\n",
    "                         learning_rate = 0.05, max_depth = 2, min_child_weight = 2, n_estimators = 1700)\n",
    "XGBmodel.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**v=0.2 Further Tuned Result**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       Fake       0.92      0.92      0.92      1071\n",
      "       Real       0.92      0.92      0.92      1020\n",
      "\n",
      "avg / total       0.92      0.92      0.92      2091\n",
      "\n",
      "Accuracy: 0.921568627451\n"
     ]
    }
   ],
   "source": [
    "y_pred = XGBmodel.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "target_names = ['Fake', 'Real']\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "print('Accuracy:',XGBmodel.score(X_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
